{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import collections\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "import evaluate\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "MAX_LENGTH = 384\n",
    "STRIDE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'squad_v2'\n",
    "raw_datasets = load_dataset(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56be85543aeaaa14008c9065',\n",
       " 'title': 'Beyoncé',\n",
       " 'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
       " 'question': 'What areas did Beyonce compete in when she was growing up?',\n",
       " 'answers': {'text': ['singing and dancing'], 'answer_start': [207]}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['King Charles III', 'King Charles III', 'King Charles III'],\n",
       " 'answer_start': [324, 324, 324]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['validation'][22]['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_training_examples(examples):\n",
    "    # Get questions from examples\n",
    "    # and remove redundant spaces\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "\n",
    "    # tokenize input data\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=\"only_second\",\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        stride=STRIDE,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    # Extract offset mappings from inputs\n",
    "    # then pop it from inputs\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "\n",
    "    # Extract sample mappings from inputs\n",
    "    # then pop it from inputs\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    # get answers from examples\n",
    "    answers = examples[\"answers\"]\n",
    "\n",
    "    # Initiate start end stop answer position list\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    # Loop through offset_mapping\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        # identify index of sample relate to the current offset\n",
    "        sample_idx = sample_map[i]\n",
    "        # get sequence_ids from input\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        # Get start and end position of context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # get answer for this sample\n",
    "        answer = answers[sample_idx]\n",
    "        if len(answer[\"text\"]) == 0:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            start_char = answer[\"answer_start\"][0]\n",
    "            end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "            # if the answer is not in the context\n",
    "            if (\n",
    "                offset[context_start][0] > start_char\n",
    "                or offset[context_end][1] < end_char\n",
    "            ):\n",
    "                start_positions.append(0)\n",
    "                end_positions.append(0)\n",
    "            else:\n",
    "                # else set the start and end position\n",
    "                idx = context_start\n",
    "                while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                    idx += 1\n",
    "                start_positions.append(idx - 1)\n",
    "                idx = context_end\n",
    "                while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                    idx -= 1\n",
    "                end_positions.append(idx + 1)\n",
    "\n",
    "    # adding start, end position to inputs\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = raw_datasets[\"train\"].map(\n",
    "    preprocess_training_examples,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130319, 131754)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_datasets[\"train\"]), len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_validation_examples(examples):\n",
    "    # Get questions from examples\n",
    "    # and remove redundant spaces\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "\n",
    "    # tokenize input data\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=\"only_second\",\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        stride=STRIDE,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Extract sample mappings from inputs\n",
    "    # then pop it from inputs\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    example_ids = []\n",
    "\n",
    "    # Xác định ví dụ tham chi ếu cho mỗi dòng đầu vào và\n",
    "    # điều chỉnh ánh xạ offset\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        # Loại bỏ các offset không phù hợp với sequence_ids\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "    # Thêm thông tin ví dụ tham chi ếu vào đầu vào\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11873, 12134)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset = raw_datasets[\"validation\"].map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"validation\"].column_names,\n",
    ")\n",
    "# In ra độ dài của raw_datasets [\" validation \"]\n",
    "# và validation_dataset để so sánh.\n",
    "len(raw_datasets[\"validation\"]), len(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('input_ids', [101, 2040, 2001, 5545, 1005, 1055, 2567, 1029, 102, 2028, 1997, 1996, 4366, 11390, 1997, 1996, 2394, 6106, 10078, 2520, 1996, 25466, 1010, 9586, 2012, 16001, 2075, 1010, 2776, 6783, 2000, 3885, 1012, 2332, 8861, 3523, 1997, 3885, 2496, 9586, 1005, 1055, 2905, 5545, 1010, 1998, 2234, 2046, 4559, 2000, 2520, 2040, 2018, 2525, 11621, 3885, 1005, 1055, 2670, 6645, 1012, 2520, 10836, 3885, 1999, 10550, 2475, 1010, 5559, 2004, 2521, 2004, 14863, 26573, 10536, 2073, 2002, 2777, 2039, 2007, 2010, 4170, 1997, 3719, 1012, 8861, 7864, 1010, 3825, 14822, 2000, 2520, 1998, 10795, 2010, 2365, 7343, 2004, 1037, 13446, 1010, 2927, 1037, 2186, 1997, 9918, 2004, 2000, 3251, 1996, 4104, 4410, 12232, 14588, 2000, 1996, 2332, 1997, 2563, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ('attention_mask', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ('offset_mapping', [None, None, None, None, None, None, None, None, None, [0, 3], [4, 6], [7, 10], [11, 16], [16, 20], [21, 23], [24, 27], [28, 35], [36, 42], [43, 51], [52, 59], [60, 63], [64, 73], [73, 74], [75, 80], [81, 83], [83, 86], [86, 89], [89, 90], [91, 101], [102, 106], [107, 109], [110, 118], [118, 119], [120, 124], [125, 132], [133, 136], [137, 139], [140, 148], [149, 156], [157, 162], [162, 163], [163, 164], [165, 171], [172, 180], [180, 181], [182, 185], [186, 190], [191, 195], [196, 206], [207, 209], [210, 217], [218, 221], [222, 225], [226, 233], [234, 242], [243, 251], [251, 252], [252, 253], [254, 262], [263, 270], [270, 271], [272, 279], [280, 287], [288, 296], [297, 299], [300, 303], [303, 304], [304, 305], [306, 312], [313, 315], [316, 319], [320, 322], [323, 326], [326, 330], [330, 332], [333, 338], [339, 341], [342, 345], [346, 348], [349, 353], [354, 357], [358, 363], [364, 366], [367, 372], [372, 373], [374, 381], [382, 391], [391, 392], [393, 397], [398, 404], [405, 407], [408, 415], [416, 419], [420, 431], [432, 435], [436, 439], [440, 446], [447, 449], [450, 451], [452, 459], [459, 460], [461, 470], [471, 472], [473, 479], [480, 482], [483, 492], [493, 495], [496, 498], [499, 506], [507, 510], [511, 519], [520, 525], [526, 530], [531, 541], [542, 544], [545, 548], [549, 553], [554, 556], [557, 564], [564, 565], None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]), ('example_id', '56de17f9cffd8e1900b4b5e0')])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset[120].items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"distilbert-finetuned-squadv2\",  \n",
    "    evaluation_strategy=\"no\",  # Chế độ đánh giá không tự động sau mỗi epoch\n",
    "    save_strategy=\"epoch\",  # Lưu checkpoint sau mỗi epoch\n",
    "    learning_rate=2e-5,  # Tốc độ học\n",
    "    num_train_epochs=5,  # Số epoch huấn luyện\n",
    "    weight_decay=0.01,  # Giảm trọng lượng mô hình để tránh overfitting\n",
    "    fp16=True,  # Sử dụng kiểu dữ liệu half - precision để tối ưu tài nguyên\n",
    "    push_to_hub=True,  # Đẩy kết quả huấn luyện lên HuggingFace Hub\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\accelerate\\accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9178933f87574eb182047d6717fba215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.254, 'grad_norm': 7.672187805175781, 'learning_rate': 1.805636540330418e-05, 'epoch': 0.49}\n",
      "{'loss': 1.5106, 'grad_norm': 8.735021591186523, 'learning_rate': 1.611273080660836e-05, 'epoch': 0.97}\n",
      "{'loss': 1.3021, 'grad_norm': 8.502686500549316, 'learning_rate': 1.4169096209912539e-05, 'epoch': 1.46}\n",
      "{'loss': 1.2261, 'grad_norm': 5.810998439788818, 'learning_rate': 1.2225461613216716e-05, 'epoch': 1.94}\n",
      "{'loss': 1.0953, 'grad_norm': 9.021493911743164, 'learning_rate': 1.0285714285714285e-05, 'epoch': 2.43}\n",
      "{'loss': 1.0653, 'grad_norm': 6.346558094024658, 'learning_rate': 8.342079689018465e-06, 'epoch': 2.91}\n",
      "{'loss': 0.9865, 'grad_norm': 6.091553688049316, 'learning_rate': 6.3984450923226434e-06, 'epoch': 3.4}\n",
      "{'loss': 0.9563, 'grad_norm': 6.82282829284668, 'learning_rate': 4.454810495626822e-06, 'epoch': 3.89}\n",
      "{'loss': 0.9044, 'grad_norm': 8.198391914367676, 'learning_rate': 2.5150631681243924e-06, 'epoch': 4.37}\n",
      "{'loss': 0.8978, 'grad_norm': 7.069595813751221, 'learning_rate': 5.714285714285715e-07, 'epoch': 4.86}\n",
      "{'train_runtime': 2725.1589, 'train_samples_per_second': 241.736, 'train_steps_per_second': 1.888, 'train_loss': 1.2107311371116527, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5145, training_loss=1.2107311371116527, metrics={'train_runtime': 2725.1589, 'train_samples_per_second': 241.736, 'train_steps_per_second': 1.888, 'total_flos': 6.452355606320333e+16, 'train_loss': 1.2107311371116527, 'epoch': 4.997571636716853})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Khởi tạo một đối tượng Trainer để huấn luyện mô hình\n",
    "trainer = Trainer(\n",
    "    model=model,  # Sử dụng mô hình đã tạo trước đó\n",
    "    args=args,  # Các tham số và cấu hình huấn luy ện\n",
    "    train_dataset=train_dataset,  # Sử dụng tập dữ liệu huấn luyện\n",
    "    eval_dataset=validation_dataset,  # Sử dụng tập dữ liệu đánh giá\n",
    "    tokenizer=tokenizer,  # Sử dụng tokenizer để xử lý văn bản\n",
    ")\n",
    "# Bắt đầu quá trình huấn luy ện\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub(commit_message=\"Reader_Squadv2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"squad_v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BEST = 20  # Số lượng kết quả tốt nhất được lựa chọn sau khi dự đoán\n",
    "MAX_ANS_LENGTH = 30  # Độ dài tối đa cho câu trả lời dự đoán\n",
    "\n",
    "\n",
    "def compute_metrics(start_logits, end_logits, features, examples):\n",
    "    # Tạo một từ điển mặc định để ánh xạ mỗi ví dụ\n",
    "    # với danh sách các đặc trưng tương ứng\n",
    "    example_to_features = collections.defaultdict(list)\n",
    "    for idx, feature in enumerate(features):\n",
    "        example_to_features[feature[\"example_id\"]].append(idx)\n",
    "        predicted_answers = []\n",
    "    for example in tqdm(examples):\n",
    "        example_id = example[\"id\"]\n",
    "        context = example[\"context\"]\n",
    "        answers = []\n",
    "        # Lặp qua tất cả các đặc trưng liên quan đến ví dụ đó\n",
    "        for feature_index in example_to_features[example_id]:\n",
    "            start_logit = start_logits[feature_index]\n",
    "            end_logit = end_logits[feature_index]\n",
    "            offsets = features[feature_index][\"offset_mapping\"]\n",
    "            # Lấy các chỉ số có giá trị lớn nhất cho start và end logits\n",
    "            start_indexes = np.argsort(start_logit)[-1 : -N_BEST - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logit)[-1 : -N_BEST - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Bỏ qua các câu trả lời\n",
    "                    # không hoàn toàn nằm trong ngữ cảnh\n",
    "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                        continue\n",
    "                    # Bỏ qua các câu trả lời có độ dài > max_answer_length\n",
    "                    if end_index - start_index + 1 > MAX_ANS_LENGTH:\n",
    "                        continue\n",
    "                    # Tạo một câu trả lời mới\n",
    "                    text = context[offsets[start_index][0] : offsets[end_index][1]]\n",
    "                    logit_score = start_logit[start_index] + end_logit[end_index]\n",
    "                    answer = {\n",
    "                        \"text\": text,\n",
    "                        \"logit_score\": logit_score,\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "        # Chọn câu trả lời có điểm số tốt nhất\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            answer_dict = {\n",
    "                \"id\": example_id,\n",
    "                \"prediction_text\": best_answer[\"text\"],\n",
    "                \"no_answer_probability\": 1 - best_answer[\"logit_score\"],\n",
    "            }\n",
    "        else:\n",
    "            answer_dict = {\n",
    "                \"id\": example_id,\n",
    "                \"prediction_text\": \"\",\n",
    "                \"no_answer_probability\": 1.0,\n",
    "            }\n",
    "        predicted_answers.append(answer_dict)\n",
    "    # Tạo danh sách câu trả lời lý thuyết từ các ví dụ\n",
    "    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n",
    "    # Sử dụng metric.compute để tính toán các độ đo và trả về kết quả\n",
    "    return metric.compute(predictions=predicted_answers, references=theoretical_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d099b167e384ee7bade2bdb77b662e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ada374af2e4122a0981fb4bf2f0520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11873 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'exact': 42.727196159353156,\n",
       " 'f1': 47.19397740890768,\n",
       " 'total': 11873,\n",
       " 'HasAns_exact': 71.64304993252361,\n",
       " 'HasAns_f1': 80.5894220269839,\n",
       " 'HasAns_total': 5928,\n",
       " 'NoAns_exact': 13.894028595458368,\n",
       " 'NoAns_f1': 13.894028595458368,\n",
       " 'NoAns_total': 5945,\n",
       " 'best_exact': 62.966394340099384,\n",
       " 'best_exact_thresh': -11.00390625,\n",
       " 'best_f1': 64.68519386646281,\n",
       " 'best_f1_thresh': -10.98828125}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Thực hiện dự đoán trên tập dữ liệu validation\n",
    "predictions, _, _ = trainer.predict(validation_dataset)\n",
    "# Lấy ra thông tin về các điểm bắt đầu và\n",
    "# điểm kết thúc của câu trả lời dự đoán\n",
    "start_logits, end_logits = predictions\n",
    "# Tính toán các chỉ số đánh giá sử dụng hàm compute_metrics\n",
    "results = compute_metrics(\n",
    "    start_logits, end_logits, validation_dataset, raw_datasets[\"validation\"]\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'squad_v2'\n",
    "raw_datasets = load_dataset(DATASET_NAME,split ='train+validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = raw_datasets.filter(lambda x: len(x['answers']['text']) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 92749\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME= 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text_input):\n",
    "    inputs = tokenizer(text_input, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    encoded_input = {key: value.to(device) for key, value in inputs.items()}\n",
    "    model_output = model(**encoded_input)\n",
    "    return model_output.last_hidden_state[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_COLUMN = 'question_embedding'\n",
    "embedding_dataset = raw_datasets.map(lambda x: {EMBEDDING_COLUMN: get_embeddings(x['question']).detach().cpu().numpy()[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "embedding_dataset.add_faiss_index(column=EMBEDDING_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1\tScore : 0.0\n",
      "Question: Why is this a bad practice?\n",
      "Context: However, performance enhancements cannot be generalized as the benefits and limitations of the system are dependent on many factors. One problem is that the system is subject to gaming. Sometimes, one person enters the destination for a large group of people going to the same floor. The dispatching algorithm is usually unable to completely cater for the variation, and latecomers may find the elevator they are assigned to is already full. Also, occasionally, one person may press the floor multiple times. This is common with up/down buttons when people believe this to be an effective way to hurry elevators. However, this will make the computer think multiple people are waiting and will allocate empty cars to serve this one person.\n",
      "\n",
      "Top 2\tScore : 4.230165481567383\n",
      "Question: Why would one want to give a speech?\n",
      "Context: Some civil disobedience defendants choose to make a defiant speech, or a speech explaining their actions, in allocution. In U.S. v. Burgos-Andujar, a defendant who was involved in a movement to stop military exercises by trespassing on U.S. Navy property argued to the court in allocution that \"the ones who are violating the greater law are the members of the Navy\". As a result, the judge increased her sentence from 40 to 60 days. This action was upheld because, according to the U.S. Court of Appeals for the First Circuit, her statement suggested a lack of remorse, an attempt to avoid responsibility for her actions, and even a likelihood of repeating her illegal actions. Some of the other allocution speeches given by the protesters complained about mistreatment from government officials.\n",
      "\n",
      "Top 3\tScore : 4.3396453857421875\n",
      "Question: How long is the typical punishment for being tardy?\n",
      "Context: A boy who is late for any division or other appointment may be required to sign \"Tardy Book\", a register kept in the School Office, between 7.35am and 7.45am, every morning for the duration of his sentence (typically three days). Tardy Book may also be issued for late work. For more serious misdeeds, a boy is summoned from his lessons to the Head Master, or Lower Master if the boy is in the lower two years, to talk personally about his misdeeds. This is known as the \"Bill\". The most serious misdeeds may result in expulsion, or rustication (suspension). Conversely, should a master be more than 15 minutes late for a class, traditionally the pupils might claim it as a \"run\" and absent themselves for the rest of its duration.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_question = \"Why is this a bad practice?\"\n",
    "input_quest_embedding = get_embeddings([input_question])\n",
    "input_quest_embedding = input_quest_embedding.cpu().detach().numpy()\n",
    "TOP_K = 3\n",
    "scores, samples = embedding_dataset.get_nearest_examples(\n",
    "    EMBEDDING_COLUMN, input_quest_embedding, k=TOP_K\n",
    ")\n",
    "\n",
    "for idx, score in enumerate(scores):\n",
    "    print(f\"Top {idx + 1}\\tScore : {score}\")\n",
    "    print(f'Question: {samples [\"question\"][ idx ]}')\n",
    "    print(f'Context: {samples [\"context\"][ idx ]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reader-Retriever QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "PIPELINE_NAME = \"question-answering\"\n",
    "MODEL_NAME = \"binhphap5/distilbert-finetuned-squadv2\"\n",
    "pipe = pipeline(PIPELINE_NAME, model=MODEL_NAME, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input question : Why is this a bad practice?\n",
      "Top 1\t Score : 0.0\n",
      "Context: However, performance enhancements cannot be generalized as the benefits and limitations of the system are dependent on many factors. One problem is that the system is subject to gaming. Sometimes, one person enters the destination for a large group of people going to the same floor. The dispatching algorithm is usually unable to completely cater for the variation, and latecomers may find the elevator they are assigned to is already full. Also, occasionally, one person may press the floor multiple times. This is common with up/down buttons when people believe this to be an effective way to hurry elevators. However, this will make the computer think multiple people are waiting and will allocate empty cars to serve this one person.\n",
      "Answer: {'score': 0.036891911178827286, 'start': 622, 'end': 683, 'answer': 'this will make the computer think multiple people are waiting'}\n",
      "\n",
      "Top 2\t Score : 4.230165481567383\n",
      "Context: Some civil disobedience defendants choose to make a defiant speech, or a speech explaining their actions, in allocution. In U.S. v. Burgos-Andujar, a defendant who was involved in a movement to stop military exercises by trespassing on U.S. Navy property argued to the court in allocution that \"the ones who are violating the greater law are the members of the Navy\". As a result, the judge increased her sentence from 40 to 60 days. This action was upheld because, according to the U.S. Court of Appeals for the First Circuit, her statement suggested a lack of remorse, an attempt to avoid responsibility for her actions, and even a likelihood of repeating her illegal actions. Some of the other allocution speeches given by the protesters complained about mistreatment from government officials.\n",
      "Answer: {'score': 0.0854639783501625, 'start': 758, 'end': 770, 'answer': 'mistreatment'}\n",
      "\n",
      "Top 3\t Score : 4.3396453857421875\n",
      "Context: A boy who is late for any division or other appointment may be required to sign \"Tardy Book\", a register kept in the School Office, between 7.35am and 7.45am, every morning for the duration of his sentence (typically three days). Tardy Book may also be issued for late work. For more serious misdeeds, a boy is summoned from his lessons to the Head Master, or Lower Master if the boy is in the lower two years, to talk personally about his misdeeds. This is known as the \"Bill\". The most serious misdeeds may result in expulsion, or rustication (suspension). Conversely, should a master be more than 15 minutes late for a class, traditionally the pupils might claim it as a \"run\" and absent themselves for the rest of its duration.\n",
      "Answer: {'score': 0.7501131296157837, 'start': 217, 'end': 227, 'answer': 'three days'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input question : {input_question}\")\n",
    "for idx, score in enumerate(scores):\n",
    "    question = samples[\"question\"][idx]\n",
    "    context = samples[\"context\"][idx]\n",
    "    answer = pipe(question=question, context=context)\n",
    "    print(f\"Top {idx + 1}\\t Score : {score}\")\n",
    "    print(f\"Context: {context}\")\n",
    "    print(f\"Answer: {answer}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## duckduckgo search api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckduckgo_search import DDGS\n",
    "\n",
    "def get_context_from_duckduckgo(question):\n",
    "    results = DDGS().text(question, max_results=2)\n",
    "    snippets = [result['body'] for result in results]\n",
    "    context = \" \".join(snippets)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.14308825135231018, 'start': 42, 'end': 100, 'answer': 'an American politician, media personality, and businessman'}\n"
     ]
    }
   ],
   "source": [
    "question = \"Who is Donald Trump ?\"\n",
    "context = get_context_from_duckduckgo(question)\n",
    "\n",
    "result = pipe(question=question, context=context)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
