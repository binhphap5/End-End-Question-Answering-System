{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import collections\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "import evaluate\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "MAX_LENGTH = 384\n",
    "STRIDE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'squad_v2'\n",
    "raw_datasets = load_dataset(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56be85543aeaaa14008c9065',\n",
       " 'title': 'Beyonc√©',\n",
       " 'context': 'Beyonc√© Giselle Knowles-Carter (/biÀêÀàj…ínse…™/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyonc√©\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
       " 'question': 'What areas did Beyonce compete in when she was growing up?',\n",
       " 'answers': {'text': ['singing and dancing'], 'answer_start': [207]}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['King Charles III', 'King Charles III', 'King Charles III'],\n",
       " 'answer_start': [324, 324, 324]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['validation'][22]['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_training_examples(examples):\n",
    "    # Get questions from examples\n",
    "    # and remove redundant spaces\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "\n",
    "    # tokenize input data\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=\"only_second\",\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        stride=STRIDE,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    # Extract offset mappings from inputs\n",
    "    # then pop it from inputs\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "\n",
    "    # Extract sample mappings from inputs\n",
    "    # then pop it from inputs\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    # get answers from examples\n",
    "    answers = examples[\"answers\"]\n",
    "\n",
    "    # Initiate start end stop answer position list\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    # Loop through offset_mapping\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        # identify index of sample relate to the current offset\n",
    "        sample_idx = sample_map[i]\n",
    "        # get sequence_ids from input\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        # Get start and end position of context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # get answer for this sample\n",
    "        answer = answers[sample_idx]\n",
    "        if len(answer[\"text\"]) == 0:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            start_char = answer[\"answer_start\"][0]\n",
    "            end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "            # if the answer is not in the context\n",
    "            if (\n",
    "                offset[context_start][0] > start_char\n",
    "                or offset[context_end][1] < end_char\n",
    "            ):\n",
    "                start_positions.append(0)\n",
    "                end_positions.append(0)\n",
    "            else:\n",
    "                # else set the start and end position\n",
    "                idx = context_start\n",
    "                while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                    idx += 1\n",
    "                start_positions.append(idx - 1)\n",
    "                idx = context_end\n",
    "                while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                    idx -= 1\n",
    "                end_positions.append(idx + 1)\n",
    "\n",
    "    # adding start, end position to inputs\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = raw_datasets[\"train\"].map(\n",
    "    preprocess_training_examples,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130319, 131754)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_datasets[\"train\"]), len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_validation_examples(examples):\n",
    "    # Get questions from examples\n",
    "    # and remove redundant spaces\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "\n",
    "    # tokenize input data\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=\"only_second\",\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        stride=STRIDE,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Extract sample mappings from inputs\n",
    "    # then pop it from inputs\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    example_ids = []\n",
    "\n",
    "    # X√°c ƒë·ªãnh v√≠ d·ª• tham chi ·∫øu cho m·ªói d√≤ng ƒë·∫ßu v√†o v√†\n",
    "    # ƒëi·ªÅu ch·ªânh √°nh x·∫° offset\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        # Lo·∫°i b·ªè c√°c offset kh√¥ng ph√π h·ª£p v·ªõi sequence_ids\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "    # Th√™m th√¥ng tin v√≠ d·ª• tham chi ·∫øu v√†o ƒë·∫ßu v√†o\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11873, 12134)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset = raw_datasets[\"validation\"].map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"validation\"].column_names,\n",
    ")\n",
    "# In ra ƒë·ªô d√†i c·ªßa raw_datasets [\" validation \"]\n",
    "# v√† validation_dataset ƒë·ªÉ so s√°nh.\n",
    "len(raw_datasets[\"validation\"]), len(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('input_ids', [101, 2040, 2001, 5545, 1005, 1055, 2567, 1029, 102, 2028, 1997, 1996, 4366, 11390, 1997, 1996, 2394, 6106, 10078, 2520, 1996, 25466, 1010, 9586, 2012, 16001, 2075, 1010, 2776, 6783, 2000, 3885, 1012, 2332, 8861, 3523, 1997, 3885, 2496, 9586, 1005, 1055, 2905, 5545, 1010, 1998, 2234, 2046, 4559, 2000, 2520, 2040, 2018, 2525, 11621, 3885, 1005, 1055, 2670, 6645, 1012, 2520, 10836, 3885, 1999, 10550, 2475, 1010, 5559, 2004, 2521, 2004, 14863, 26573, 10536, 2073, 2002, 2777, 2039, 2007, 2010, 4170, 1997, 3719, 1012, 8861, 7864, 1010, 3825, 14822, 2000, 2520, 1998, 10795, 2010, 2365, 7343, 2004, 1037, 13446, 1010, 2927, 1037, 2186, 1997, 9918, 2004, 2000, 3251, 1996, 4104, 4410, 12232, 14588, 2000, 1996, 2332, 1997, 2563, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ('attention_mask', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ('offset_mapping', [None, None, None, None, None, None, None, None, None, [0, 3], [4, 6], [7, 10], [11, 16], [16, 20], [21, 23], [24, 27], [28, 35], [36, 42], [43, 51], [52, 59], [60, 63], [64, 73], [73, 74], [75, 80], [81, 83], [83, 86], [86, 89], [89, 90], [91, 101], [102, 106], [107, 109], [110, 118], [118, 119], [120, 124], [125, 132], [133, 136], [137, 139], [140, 148], [149, 156], [157, 162], [162, 163], [163, 164], [165, 171], [172, 180], [180, 181], [182, 185], [186, 190], [191, 195], [196, 206], [207, 209], [210, 217], [218, 221], [222, 225], [226, 233], [234, 242], [243, 251], [251, 252], [252, 253], [254, 262], [263, 270], [270, 271], [272, 279], [280, 287], [288, 296], [297, 299], [300, 303], [303, 304], [304, 305], [306, 312], [313, 315], [316, 319], [320, 322], [323, 326], [326, 330], [330, 332], [333, 338], [339, 341], [342, 345], [346, 348], [349, 353], [354, 357], [358, 363], [364, 366], [367, 372], [372, 373], [374, 381], [382, 391], [391, 392], [393, 397], [398, 404], [405, 407], [408, 415], [416, 419], [420, 431], [432, 435], [436, 439], [440, 446], [447, 449], [450, 451], [452, 459], [459, 460], [461, 470], [471, 472], [473, 479], [480, 482], [483, 492], [493, 495], [496, 498], [499, 506], [507, 510], [511, 519], [520, 525], [526, 530], [531, 541], [542, 544], [545, 548], [549, 553], [554, 556], [557, 564], [564, 565], None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]), ('example_id', '56de17f9cffd8e1900b4b5e0')])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset[120].items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"distilbert-finetuned-squadv2\",  \n",
    "    evaluation_strategy=\"no\",  # Ch·∫ø ƒë·ªô ƒë√°nh gi√° kh√¥ng t·ª± ƒë·ªông sau m·ªói epoch\n",
    "    save_strategy=\"epoch\",  # L∆∞u checkpoint sau m·ªói epoch\n",
    "    learning_rate=2e-5,  # T·ªëc ƒë·ªô h·ªçc\n",
    "    num_train_epochs=5,  # S·ªë epoch hu·∫•n luy·ªán\n",
    "    weight_decay=0.01,  # Gi·∫£m tr·ªçng l∆∞·ª£ng m√¥ h√¨nh ƒë·ªÉ tr√°nh overfitting\n",
    "    fp16=True,  # S·ª≠ d·ª•ng ki·ªÉu d·ªØ li·ªáu half - precision ƒë·ªÉ t·ªëi ∆∞u t√†i nguy√™n\n",
    "    push_to_hub=True,  # ƒê·∫©y k·∫øt qu·∫£ hu·∫•n luy·ªán l√™n HuggingFace Hub\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\accelerate\\accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9178933f87574eb182047d6717fba215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.254, 'grad_norm': 7.672187805175781, 'learning_rate': 1.805636540330418e-05, 'epoch': 0.49}\n",
      "{'loss': 1.5106, 'grad_norm': 8.735021591186523, 'learning_rate': 1.611273080660836e-05, 'epoch': 0.97}\n",
      "{'loss': 1.3021, 'grad_norm': 8.502686500549316, 'learning_rate': 1.4169096209912539e-05, 'epoch': 1.46}\n",
      "{'loss': 1.2261, 'grad_norm': 5.810998439788818, 'learning_rate': 1.2225461613216716e-05, 'epoch': 1.94}\n",
      "{'loss': 1.0953, 'grad_norm': 9.021493911743164, 'learning_rate': 1.0285714285714285e-05, 'epoch': 2.43}\n",
      "{'loss': 1.0653, 'grad_norm': 6.346558094024658, 'learning_rate': 8.342079689018465e-06, 'epoch': 2.91}\n",
      "{'loss': 0.9865, 'grad_norm': 6.091553688049316, 'learning_rate': 6.3984450923226434e-06, 'epoch': 3.4}\n",
      "{'loss': 0.9563, 'grad_norm': 6.82282829284668, 'learning_rate': 4.454810495626822e-06, 'epoch': 3.89}\n",
      "{'loss': 0.9044, 'grad_norm': 8.198391914367676, 'learning_rate': 2.5150631681243924e-06, 'epoch': 4.37}\n",
      "{'loss': 0.8978, 'grad_norm': 7.069595813751221, 'learning_rate': 5.714285714285715e-07, 'epoch': 4.86}\n",
      "{'train_runtime': 2725.1589, 'train_samples_per_second': 241.736, 'train_steps_per_second': 1.888, 'train_loss': 1.2107311371116527, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5145, training_loss=1.2107311371116527, metrics={'train_runtime': 2725.1589, 'train_samples_per_second': 241.736, 'train_steps_per_second': 1.888, 'total_flos': 6.452355606320333e+16, 'train_loss': 1.2107311371116527, 'epoch': 4.997571636716853})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kh·ªüi t·∫°o m·ªôt ƒë·ªëi t∆∞·ª£ng Trainer ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh\n",
    "trainer = Trainer(\n",
    "    model=model,  # S·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ t·∫°o tr∆∞·ªõc ƒë√≥\n",
    "    args=args,  # C√°c tham s·ªë v√† c·∫•u h√¨nh hu·∫•n luy ·ªán\n",
    "    train_dataset=train_dataset,  # S·ª≠ d·ª•ng t·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán\n",
    "    eval_dataset=validation_dataset,  # S·ª≠ d·ª•ng t·∫≠p d·ªØ li·ªáu ƒë√°nh gi√°\n",
    "    tokenizer=tokenizer,  # S·ª≠ d·ª•ng tokenizer ƒë·ªÉ x·ª≠ l√Ω vƒÉn b·∫£n\n",
    ")\n",
    "# B·∫Øt ƒë·∫ßu qu√° tr√¨nh hu·∫•n luy ·ªán\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub(commit_message=\"Reader_Squadv2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"squad_v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BEST = 20  # S·ªë l∆∞·ª£ng k·∫øt qu·∫£ t·ªët nh·∫•t ƒë∆∞·ª£c l·ª±a ch·ªçn sau khi d·ª± ƒëo√°n\n",
    "MAX_ANS_LENGTH = 30  # ƒê·ªô d√†i t·ªëi ƒëa cho c√¢u tr·∫£ l·ªùi d·ª± ƒëo√°n\n",
    "\n",
    "\n",
    "def compute_metrics(start_logits, end_logits, features, examples):\n",
    "    # T·∫°o m·ªôt t·ª´ ƒëi·ªÉn m·∫∑c ƒë·ªãnh ƒë·ªÉ √°nh x·∫° m·ªói v√≠ d·ª•\n",
    "    # v·ªõi danh s√°ch c√°c ƒë·∫∑c tr∆∞ng t∆∞∆°ng ·ª©ng\n",
    "    example_to_features = collections.defaultdict(list)\n",
    "    for idx, feature in enumerate(features):\n",
    "        example_to_features[feature[\"example_id\"]].append(idx)\n",
    "        predicted_answers = []\n",
    "    for example in tqdm(examples):\n",
    "        example_id = example[\"id\"]\n",
    "        context = example[\"context\"]\n",
    "        answers = []\n",
    "        # L·∫∑p qua t·∫•t c·∫£ c√°c ƒë·∫∑c tr∆∞ng li√™n quan ƒë·∫øn v√≠ d·ª• ƒë√≥\n",
    "        for feature_index in example_to_features[example_id]:\n",
    "            start_logit = start_logits[feature_index]\n",
    "            end_logit = end_logits[feature_index]\n",
    "            offsets = features[feature_index][\"offset_mapping\"]\n",
    "            # L·∫•y c√°c ch·ªâ s·ªë c√≥ gi√° tr·ªã l·ªõn nh·∫•t cho start v√† end logits\n",
    "            start_indexes = np.argsort(start_logit)[-1 : -N_BEST - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logit)[-1 : -N_BEST - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # B·ªè qua c√°c c√¢u tr·∫£ l·ªùi\n",
    "                    # kh√¥ng ho√†n to√†n n·∫±m trong ng·ªØ c·∫£nh\n",
    "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                        continue\n",
    "                    # B·ªè qua c√°c c√¢u tr·∫£ l·ªùi c√≥ ƒë·ªô d√†i > max_answer_length\n",
    "                    if end_index - start_index + 1 > MAX_ANS_LENGTH:\n",
    "                        continue\n",
    "                    # T·∫°o m·ªôt c√¢u tr·∫£ l·ªùi m·ªõi\n",
    "                    text = context[offsets[start_index][0] : offsets[end_index][1]]\n",
    "                    logit_score = start_logit[start_index] + end_logit[end_index]\n",
    "                    answer = {\n",
    "                        \"text\": text,\n",
    "                        \"logit_score\": logit_score,\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "        # Ch·ªçn c√¢u tr·∫£ l·ªùi c√≥ ƒëi·ªÉm s·ªë t·ªët nh·∫•t\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            answer_dict = {\n",
    "                \"id\": example_id,\n",
    "                \"prediction_text\": best_answer[\"text\"],\n",
    "                \"no_answer_probability\": 1 - best_answer[\"logit_score\"],\n",
    "            }\n",
    "        else:\n",
    "            answer_dict = {\n",
    "                \"id\": example_id,\n",
    "                \"prediction_text\": \"\",\n",
    "                \"no_answer_probability\": 1.0,\n",
    "            }\n",
    "        predicted_answers.append(answer_dict)\n",
    "    # T·∫°o danh s√°ch c√¢u tr·∫£ l·ªùi l√Ω thuy·∫øt t·ª´ c√°c v√≠ d·ª•\n",
    "    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n",
    "    # S·ª≠ d·ª•ng metric.compute ƒë·ªÉ t√≠nh to√°n c√°c ƒë·ªô ƒëo v√† tr·∫£ v·ªÅ k·∫øt qu·∫£\n",
    "    return metric.compute(predictions=predicted_answers, references=theoretical_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d099b167e384ee7bade2bdb77b662e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ada374af2e4122a0981fb4bf2f0520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11873 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'exact': 42.727196159353156,\n",
       " 'f1': 47.19397740890768,\n",
       " 'total': 11873,\n",
       " 'HasAns_exact': 71.64304993252361,\n",
       " 'HasAns_f1': 80.5894220269839,\n",
       " 'HasAns_total': 5928,\n",
       " 'NoAns_exact': 13.894028595458368,\n",
       " 'NoAns_f1': 13.894028595458368,\n",
       " 'NoAns_total': 5945,\n",
       " 'best_exact': 62.966394340099384,\n",
       " 'best_exact_thresh': -11.00390625,\n",
       " 'best_f1': 64.68519386646281,\n",
       " 'best_f1_thresh': -10.98828125}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Th·ª±c hi·ªán d·ª± ƒëo√°n tr√™n t·∫≠p d·ªØ li·ªáu validation\n",
    "predictions, _, _ = trainer.predict(validation_dataset)\n",
    "# L·∫•y ra th√¥ng tin v·ªÅ c√°c ƒëi·ªÉm b·∫Øt ƒë·∫ßu v√†\n",
    "# ƒëi·ªÉm k·∫øt th√∫c c·ªßa c√¢u tr·∫£ l·ªùi d·ª± ƒëo√°n\n",
    "start_logits, end_logits = predictions\n",
    "# T√≠nh to√°n c√°c ch·ªâ s·ªë ƒë√°nh gi√° s·ª≠ d·ª•ng h√†m compute_metrics\n",
    "results = compute_metrics(\n",
    "    start_logits, end_logits, validation_dataset, raw_datasets[\"validation\"]\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'squad_v2'\n",
    "raw_datasets = load_dataset(DATASET_NAME,split ='train+validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = raw_datasets.filter(lambda x: len(x['answers']['text']) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 92749\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME= 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text_input):\n",
    "    inputs = tokenizer(text_input, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    encoded_input = {key: value.to(device) for key, value in inputs.items()}\n",
    "    model_output = model(**encoded_input)\n",
    "    return model_output.last_hidden_state[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_COLUMN = 'question_embedding'\n",
    "embedding_dataset = raw_datasets.map(lambda x: {EMBEDDING_COLUMN: get_embeddings(x['question']).detach().cpu().numpy()[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "embedding_dataset.add_faiss_index(column=EMBEDDING_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1\tScore : 0.0\n",
      "Question: Why is this a bad practice?\n",
      "Context: However, performance enhancements cannot be generalized as the benefits and limitations of the system are dependent on many factors. One problem is that the system is subject to gaming. Sometimes, one person enters the destination for a large group of people going to the same floor. The dispatching algorithm is usually unable to completely cater for the variation, and latecomers may find the elevator they are assigned to is already full. Also, occasionally, one person may press the floor multiple times. This is common with up/down buttons when people believe this to be an effective way to hurry elevators. However, this will make the computer think multiple people are waiting and will allocate empty cars to serve this one person.\n",
      "\n",
      "Top 2\tScore : 4.230165481567383\n",
      "Question: Why would one want to give a speech?\n",
      "Context: Some civil disobedience defendants choose to make a defiant speech, or a speech explaining their actions, in allocution. In U.S. v. Burgos-Andujar, a defendant who was involved in a movement to stop military exercises by trespassing on U.S. Navy property argued to the court in allocution that \"the ones who are violating the greater law are the members of the Navy\". As a result, the judge increased her sentence from 40 to 60 days. This action was upheld because, according to the U.S. Court of Appeals for the First Circuit, her statement suggested a lack of remorse, an attempt to avoid responsibility for her actions, and even a likelihood of repeating her illegal actions. Some of the other allocution speeches given by the protesters complained about mistreatment from government officials.\n",
      "\n",
      "Top 3\tScore : 4.3396453857421875\n",
      "Question: How long is the typical punishment for being tardy?\n",
      "Context: A boy who is late for any division or other appointment may be required to sign \"Tardy Book\", a register kept in the School Office, between 7.35am and 7.45am, every morning for the duration of his sentence (typically three days). Tardy Book may also be issued for late work. For more serious misdeeds, a boy is summoned from his lessons to the Head Master, or Lower Master if the boy is in the lower two years, to talk personally about his misdeeds. This is known as the \"Bill\". The most serious misdeeds may result in expulsion, or rustication (suspension). Conversely, should a master be more than 15 minutes late for a class, traditionally the pupils might claim it as a \"run\" and absent themselves for the rest of its duration.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_question = \"Why is this a bad practice?\"\n",
    "input_quest_embedding = get_embeddings([input_question])\n",
    "input_quest_embedding = input_quest_embedding.cpu().detach().numpy()\n",
    "TOP_K = 3\n",
    "scores, samples = embedding_dataset.get_nearest_examples(\n",
    "    EMBEDDING_COLUMN, input_quest_embedding, k=TOP_K\n",
    ")\n",
    "\n",
    "for idx, score in enumerate(scores):\n",
    "    print(f\"Top {idx + 1}\\tScore : {score}\")\n",
    "    print(f'Question: {samples [\"question\"][ idx ]}')\n",
    "    print(f'Context: {samples [\"context\"][ idx ]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reader-Retriever QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "PIPELINE_NAME = \"question-answering\"\n",
    "MODEL_NAME = \"binhphap5/distilbert-finetuned-squadv2\"\n",
    "pipe = pipeline(PIPELINE_NAME, model=MODEL_NAME, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input question : Why is this a bad practice?\n",
      "Top 1\t Score : 0.0\n",
      "Context: However, performance enhancements cannot be generalized as the benefits and limitations of the system are dependent on many factors. One problem is that the system is subject to gaming. Sometimes, one person enters the destination for a large group of people going to the same floor. The dispatching algorithm is usually unable to completely cater for the variation, and latecomers may find the elevator they are assigned to is already full. Also, occasionally, one person may press the floor multiple times. This is common with up/down buttons when people believe this to be an effective way to hurry elevators. However, this will make the computer think multiple people are waiting and will allocate empty cars to serve this one person.\n",
      "Answer: {'score': 0.036891911178827286, 'start': 622, 'end': 683, 'answer': 'this will make the computer think multiple people are waiting'}\n",
      "\n",
      "Top 2\t Score : 4.230165481567383\n",
      "Context: Some civil disobedience defendants choose to make a defiant speech, or a speech explaining their actions, in allocution. In U.S. v. Burgos-Andujar, a defendant who was involved in a movement to stop military exercises by trespassing on U.S. Navy property argued to the court in allocution that \"the ones who are violating the greater law are the members of the Navy\". As a result, the judge increased her sentence from 40 to 60 days. This action was upheld because, according to the U.S. Court of Appeals for the First Circuit, her statement suggested a lack of remorse, an attempt to avoid responsibility for her actions, and even a likelihood of repeating her illegal actions. Some of the other allocution speeches given by the protesters complained about mistreatment from government officials.\n",
      "Answer: {'score': 0.0854639783501625, 'start': 758, 'end': 770, 'answer': 'mistreatment'}\n",
      "\n",
      "Top 3\t Score : 4.3396453857421875\n",
      "Context: A boy who is late for any division or other appointment may be required to sign \"Tardy Book\", a register kept in the School Office, between 7.35am and 7.45am, every morning for the duration of his sentence (typically three days). Tardy Book may also be issued for late work. For more serious misdeeds, a boy is summoned from his lessons to the Head Master, or Lower Master if the boy is in the lower two years, to talk personally about his misdeeds. This is known as the \"Bill\". The most serious misdeeds may result in expulsion, or rustication (suspension). Conversely, should a master be more than 15 minutes late for a class, traditionally the pupils might claim it as a \"run\" and absent themselves for the rest of its duration.\n",
      "Answer: {'score': 0.7501131296157837, 'start': 217, 'end': 227, 'answer': 'three days'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input question : {input_question}\")\n",
    "for idx, score in enumerate(scores):\n",
    "    question = samples[\"question\"][idx]\n",
    "    context = samples[\"context\"][idx]\n",
    "    answer = pipe(question=question, context=context)\n",
    "    print(f\"Top {idx + 1}\\t Score : {score}\")\n",
    "    print(f\"Context: {context}\")\n",
    "    print(f\"Answer: {answer}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## duckduckgo search api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckduckgo_search import DDGS\n",
    "\n",
    "def get_context_from_duckduckgo(question):\n",
    "    results = DDGS().text(question, max_results=2)\n",
    "    snippets = [result['body'] for result in results]\n",
    "    context = \" \".join(snippets)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.14308825135231018, 'start': 42, 'end': 100, 'answer': 'an American politician, media personality, and businessman'}\n"
     ]
    }
   ],
   "source": [
    "question = \"Who is Donald Trump ?\"\n",
    "context = get_context_from_duckduckgo(question)\n",
    "\n",
    "result = pipe(question=question, context=context)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
